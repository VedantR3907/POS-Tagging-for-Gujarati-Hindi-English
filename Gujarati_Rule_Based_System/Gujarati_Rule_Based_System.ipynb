{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> Gujarati POS TAGGING </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> Word and Sentence Tokenization </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word Tokenization\n",
    "def WordTokenizer(data, keep_punctuations=False):\n",
    "    if not keep_punctuations:\n",
    "        data = re.sub(r'[.?/,:;*\\\"!+$#@%^&~\\(\\)]','',data)\n",
    "\n",
    "    data = re.sub(r'([.,\\'\\\\\"!?%#@*<>|\\+\\-\\(\\)])', r' \\1', data)\n",
    "    data = re.sub(r'[।।(૧૨૩૪૫૬૭૮૯)*।।]', '  ', data)\n",
    "    data = re.sub(r'[।।(123456789)*।।]', '  ', data)\n",
    "    data = re.sub(r\"   \", '', data)\n",
    "    data = re.sub(r'…', \" \", data)\n",
    "    data = re.split(r'[ -]',data)\n",
    "    return_list = []\n",
    "\n",
    "    for i in data:\n",
    "        if i:\n",
    "            return_list.append(i)\n",
    "            \n",
    "\n",
    "    return return_list\n",
    "\n",
    "#Sentence tokenization\n",
    "def SentenceTokenizer(data):\n",
    "    data = data.strip()\n",
    "    data = data.strip('\\n')\n",
    "    data = re.sub(r'([.!?])', r'\\1 ', data)\n",
    "    data = re.split(r'  ',data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading the Stop Words Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"C:/Users/vedan/Downloads/pos tagg vedant/POS Tagging-20230926T042149Z-001/POS Tagging/Gujarati_new_stopwords.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gujarati_Tokens</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>તેથી</td>\n",
       "      <td>Conjunction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>આપણું</td>\n",
       "      <td>Pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ખાણ</td>\n",
       "      <td>Verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>આપણો</td>\n",
       "      <td>Pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>હવે</td>\n",
       "      <td>Adverb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gujarati_Tokens         Tags\n",
       "0            તેથી  Conjunction\n",
       "1           આપણું      Pronoun\n",
       "2             ખાણ         Verb\n",
       "3            આપણો      Pronoun\n",
       "4             હવે       Adverb"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write your own sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'મારો મિત્ર# @ ગમ્યો છે મહેનત થી વેદાંત!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['મારો મિત્ર# @ ગમ્યો છે મહેનત થી વેદાંત! ']"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sentence Tokenization\n",
    "tokenized_sentence = SentenceTokenizer(sentence)\n",
    "tokenized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['મારો', 'મિત્ર', 'ગમ્યો', 'છે', 'મહેનત', 'થી', 'વેદાંત']]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word Tokenization\n",
    "tokenized = [WordTokenizer(i) for i in tokenized_sentence]\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Dictonary for gujarati words with there respective pos tags from the dataset\n",
    "\n",
    "pos_tags = dict()\n",
    "tags_list = [[] for i in range(len(tokenized))]\n",
    "count = 0\n",
    "for i in tokenized:\n",
    "    for j in i:\n",
    "        if j in data['Gujarati_Tokens'].values and j not in pos_tags:\n",
    "            tag = data.loc[data['Gujarati_Tokens'] ==j, 'Tags'].values[0]\n",
    "            pos_tags[j] = tag\n",
    "            tags_list[count].append(tag)\n",
    "        else:\n",
    "            if j not in data['Gujarati_Tokens'].values:\n",
    "                pos_tags[j] = 'Missing'\n",
    "                tags_list[count].append('Unknown')\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of sentence: - [7]\n"
     ]
    }
   ],
   "source": [
    "sentences_lens = [len(i) for i in tags_list]\n",
    "print(f'Total length of sentence: - {sentences_lens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'મારો': 'Preposition',\n",
       " 'મિત્ર': 'Noun',\n",
       " 'ગમ્યો': 'Missing',\n",
       " 'છે': 'Verb',\n",
       " 'મહેનત': 'Noun',\n",
       " 'થી': 'Adjective',\n",
       " 'વેદાંત': 'Noun'}"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Preposition', 'Noun', 'Unknown', 'Verb', 'Noun', 'Adjective', 'Noun']]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_word_sentences = list(pos_tags.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Rules for Tags </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_before = ''\n",
    "rules_applied_list = {} \n",
    "count,sent,next_word,rules_applied = 0,0,0,0\n",
    "for i,j in pos_tags.items():\n",
    "    count += 1\n",
    "    if i[-2:] == 'યો' or i[-2:] == 'યુ' or i[-4:] == 'ય ું':\n",
    "        rules_applied_list[i] = [j]\n",
    "        pos_tags[i] = 'Verb'\n",
    "        rules_applied += 1\n",
    "        rules_applied_list[i].append(pos_tags[i])\n",
    "\n",
    "    if i[-4:] == 'વ ું' or i[-4:] == 'વ ુ':\n",
    "        rules_applied_list[i] = [j]\n",
    "        pos_tags[i] = 'Verb'\n",
    "        rules_applied += 1\n",
    "        rules_applied_list[i].append(pos_tags[i])\n",
    "\n",
    "    if i[-2:] == \"ીશ\" or i[-4:] == 'ીશું' or i[-2:] == 'શે':\n",
    "        if count == sentences_lens[sent]:\n",
    "            rules_applied_list[i] = [j]\n",
    "            pos_tags[i] = 'Verb'\n",
    "            count = 0\n",
    "            sent += 1\n",
    "            rules_applied += 1\n",
    "            rules_applied_list[i].append(pos_tags[i])\n",
    "\n",
    "    if i[-4:] == 'વાયો':\n",
    "        rules_applied_list[i] = [j]\n",
    "        pos_tags[i] = 'Verb'\n",
    "        rules_applied += 1\n",
    "        rules_applied_list[i].append(pos_tags[i])\n",
    "\n",
    "    if i == 'નથી' or i == 'ને' or i == 'ન' or i == 'ના':\n",
    "        if count != sentences_lens[sent]:\n",
    "            rules_applied_list[i] = [j]\n",
    "            pos_tags[next_word_sentences[next_word+1]] = 'Verb'\n",
    "            count = 0\n",
    "            sent += 1\n",
    "            rules_applied += 1\n",
    "            rules_applied_list[i].append(pos_tags[i])\n",
    "\n",
    "    if i[-2:] == 'થી' or i[-2:] == 'તમ' or i[-2:] == 'માું':\n",
    "        rules_applied_list[i] = [j]\n",
    "        pos_tags[i] = 'Adverb'\n",
    "        rules_applied += 1\n",
    "        rules_applied_list[i].append(pos_tags[i])\n",
    "\n",
    "    if i[:] == 'આ' or i[:] == 'એક':\n",
    "        rules_applied_list[i] = [j]\n",
    "        pos_tags[i] = 'Determiner'\n",
    "        rules_applied += 1\n",
    "        rules_applied_list[i].append(pos_tags[i])\n",
    "\n",
    "    if i[:]=='!' or i[:]=='?' or i[:]==',' or i[:]=='.' or i[:]=='' or i[:]=='\"\"' or i[:]==';' or i[:]==':' or i[:]==' '' ' or i[:]=='-':\n",
    "        rules_applied_list[i] = [j]\n",
    "        pos_tags[i] = 'Punctuations'\n",
    "        rules_applied += 1\n",
    "        rules_applied_list[i].append(pos_tags[i])\n",
    "    \n",
    "    if j == 'Adjective':\n",
    "        if pos_tags[next_word_sentences[next_word+1]] == 'Missing':\n",
    "            rules_applied_list[i] = [j]\n",
    "            pos_tags[next_word_sentences[next_word+1]] = 'Noun'\n",
    "            rules_applied_list[i].append(pos_tags[i])\n",
    "\n",
    "    next_word += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rules Applied: - 2\n",
      "\n",
      "મારો\t------▶\tPreposition\n",
      "મિત્ર\t------▶\tNoun\n",
      "ગમ્યો\t------▶\tVerb\n",
      "છે\t------▶\tVerb\n",
      "મહેનત\t------▶\tNoun\n",
      "થી\t------▶\tAdverb\n",
      "વેદાંત\t------▶\tNoun\n",
      "\n",
      "\n",
      "\n",
      "***** RULES APPLIED *****\n",
      "\n",
      "ગમ્યો\t----▶  Missing\t----▶  Verb\n",
      "થી\t----▶  Adjective\t----▶  Adverb\n"
     ]
    }
   ],
   "source": [
    "sentence = list(pos_tags.keys())\n",
    "final_tags = list(pos_tags.values())\n",
    "\n",
    "print(f'Rules Applied: - {rules_applied}\\n')\n",
    "for i in range(len(sentence)):\n",
    "    print(f'{sentence[i]}\\t------▶\\t{final_tags[i]}')\n",
    "\n",
    "print('\\n\\n')\n",
    "print(\"***** RULES APPLIED *****\\n\")\n",
    "for i,j in rules_applied_list.items():\n",
    "    print(f'{i}\\t----▶  {j[0]}\\t----▶  {j[1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
